{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drfengze/ANN-CBIR/blob/main/1.2_training_dataset_corn_sentinelonly_june1_julyend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKrQAmSQr4uq"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FykuLjxvx_97",
        "outputId": "b9090933-bbab-4fe5-a52a-658ed8733146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=5PEjbZ2a9X3cUUilgpFZiPnX3T09xvwLr8lsUY7SQoY&tc=-8iRbCBH46fqXOHr4n7O8IuMcOZnpFwXOHjTXtvGioE&cc=TxdF4lF8s1xJSXPOgno-lR7TFBozLp-vkjwvBOig7gQ\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1Adeu5BVHafk2C2WEAXXyGRhjw-FQdOr11w5b_cyqwDZyWKaxC4f5HatauxA\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "import ee\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta, date\n",
        "import random\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D11a9rtVSqY6",
        "outputId": "a8c92283-e37e-447a-ad6a-69b23495d4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloud masking function.\n",
        "def maskL8sr(image):\n",
        "    cloudShadowBitMask = ee.Number(2).pow(4).int()\n",
        "    cloudsBitMask = ee.Number(2).pow(3).int()\n",
        "    qa = image.select(\"QA_PIXEL\")\n",
        "    mask1 = (\n",
        "        qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "    )\n",
        "    mask2 = image.mask().reduce(\"min\")\n",
        "    # mask3 = image.select(opticalBands).gt(0).And(\n",
        "    #     image.select(opticalBands).lt(10000)).reduce('min')\n",
        "    mask = mask1.And(mask2)  # .And(mask3)\n",
        "    return image.updateMask(mask)\n",
        "\n",
        "\n",
        "# Cloud masking function for s2\n",
        "def maskS2clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "    cloudBitMask = 1 << 10\n",
        "    cirrusBitMask = 1 << 11\n",
        "    # Both flags should be set to zero, indicating clear conditions.\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0) \\\n",
        "        .And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "\n",
        "    return image.updateMask(mask)\n",
        "\n",
        "\n",
        "def merge_s2_l8(s2, l8):\n",
        "    merged = ee.ImageCollection([s2, l8]).mean()\n",
        "    return merged\n",
        "\n",
        "def filter_type(cdl):\n",
        "    return cdl.eq(1).selfMask().multiply(1).unmask().add(cdl.eq(5).selfMask().multiply(1).unmask())\n",
        "\n",
        "def img_vi(img):\n",
        "    img = img.addBands(img.normalizedDifference([\"nir\", \"red\"]).rename(\"ndvi\"))\n",
        "    img = img.addBands(img.select([\"ndvi\"]).multiply(img.select([\"nir\"])).rename(\"nirv\"))\n",
        "    return img"
      ],
      "metadata": {
        "id": "FZM0MmyMS999"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6B1S_5ANZLdB"
      },
      "outputs": [],
      "source": [
        "bandNamesOut = [\"blue\", \"green\", \"red\", \"nir\", \"swir1\", \"swir2\"]\n",
        "bandNamesl8 = [\"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B6\", \"SR_B7\"]\n",
        "bandNamesS2 = [\"B2\", \"B3\", \"B4\", \"B8\", \"B11\", \"B12\"]\n",
        "BANDS = [\"blue\", \"green\", \"red\", \"nir\", \"swir1\", \"swir2\", \"ndvi\", \"nirv\"]\n",
        "RESPONSE = \"cropland\"\n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 128\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "l8sr = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\").map(maskL8sr)\n",
        "l8sr = l8sr.select(bandNamesl8, bandNamesOut)\n",
        "\n",
        "s2Sr = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\").map(maskS2clouds)\n",
        "s2Sr = s2Sr.select(bandNamesS2, bandNamesOut)\n",
        "# df = pd.read_csv('/content/drive/MyDrive/RDA/model_and_env/calendar.csv')\n",
        "country = 'United States of America'\n",
        "crop = 'Corn Soybean'\n",
        "# calendar = df.loc[(df['Country'] == country) & (df['Crop'] == crop)].to_dict(orient='records')[0]\n",
        "us = ee.FeatureCollection(\"FAO/GAUL_SIMPLIFIED_500m/2015/level1\").filter(\n",
        "    'ADM0_NAME == \"{}\"'.format(country)\n",
        ")\n",
        "states = ['Iowa', 'Illinois', 'Indiana', 'Michigan', 'Ohio', 'Nebraska', 'Kansas', 'Minnesota', 'Missouri']\n",
        "trainingPolys = us.filter(ee.Filter.inList(\"ADM1_NAME\", states))\n",
        "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
        "\n",
        "\"\"\"# Data Preparation\"\"\"\n",
        "FOLDER = \"{}_{}\".format(crop,country).replace(' ','_')\n",
        "TRAINING_BASE = \"training_{}\".format(crop).replace(' ','_')\n",
        "EVAL_BASE = \"eval_patches\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XE2jODj-eT_R"
      },
      "outputs": [],
      "source": [
        "class DATA_EXPORTER:\n",
        "  def __init__(self, image, cdl, kernel, randomseed, binary,scale,FOLDER):\n",
        "      self.image = image\n",
        "      self.cdl = cdl\n",
        "      self.kernel = kernel\n",
        "      self.randomseed = randomseed\n",
        "      self.binary = binary\n",
        "      # self.classcode = classcode\n",
        "      self.folder = FOLDER\n",
        "      self.scale = scale\n",
        "\n",
        "\n",
        "  def export(self):\n",
        "      wheat_lc = filter_type(self.cdl)\n",
        "      mask = wheat_lc.neq(0)\n",
        "      if self.binary:\n",
        "          featureStack = ee.Image.cat([self.image, wheat_lc.select(\"cropland\")]).float()\n",
        "          # self.cdl_export(wheat_lc,self.description,self.trainingPoly)\n",
        "      else:\n",
        "          featureStack = ee.Image.cat([self.image, self.cdl.select(\"cropland\")]).float()\n",
        "          # self.cdl_export(self.cdl,self.description,self.trainingPoly)\n",
        "      arrays = featureStack.neighborhoodToArray(self.kernel)\n",
        "      arrays_masked = arrays.updateMask(mask)\n",
        "      return arrays_masked,wheat_lc\n",
        "\n",
        "  def train_export(self,trainingPoly,desc,n=200):\n",
        "      '''\n",
        "      arrays: image collection\n",
        "      trainingPoly: polygon to sample\n",
        "      n: number of samples\n",
        "      folder: folder to save to\n",
        "      desc: description of task\n",
        "      i: seed\n",
        "      '''\n",
        "      arrays,_ = self.export()\n",
        "      geomSample = ee.FeatureCollection([])\n",
        "      for j in np.arange(n):\n",
        "          sample = arrays.sample(\n",
        "              region=trainingPoly,\n",
        "              numPixels=20,  # Size of the shard.\n",
        "              seed=random.randint(0, 10*n),\n",
        "              scale=self.scale,\n",
        "              tileScale=8,\n",
        "          )\n",
        "          geomSample = geomSample.merge(sample)\n",
        "\n",
        "      task = ee.batch.Export.table.toDrive(\n",
        "          folder=self.folder,\n",
        "          collection=geomSample,\n",
        "          description='train_'+desc,\n",
        "          fileFormat=\"TFRecord\",\n",
        "      )\n",
        "      task.start()\n",
        "\n",
        "  # def cdl_export(self,desc,trainingPoly):\n",
        "  #     _,wheat_lc = self.export()\n",
        "  #     exportTask = ee.batch.Export.image.toDrive(\n",
        "  #         image=wheat_lc,\n",
        "  #         folder=self.folder,\n",
        "  #         description='cdl_'+desc,\n",
        "  #         scale=30,\n",
        "  #         maxPixels = 1e10,\n",
        "  #         region=trainingPoly.geometry(),\n",
        "  #         fileFormat='GeoTIFF'\n",
        "  #         )\n",
        "  #     exportTask.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HsuS8bQVUJkO"
      },
      "outputs": [],
      "source": [
        "binary = True\n",
        "FOLDER = \"{}_{}_{}\".format(crop,country,str(binary)).replace(' ','_')\n",
        "list1 = ee.List.repeat(1, KERNEL_SIZE)\n",
        "lists = ee.List.repeat(list1, KERNEL_SIZE)\n",
        "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "for YEAR in range(2017, 2023):\n",
        "    # using the calendar to get two months before harvest\n",
        "    dte1 = date(YEAR, 6, 1)\n",
        "    l8_growend = date(YEAR, 7,18)\n",
        "    s2_growend = date(YEAR, 8,1)\n",
        "    l8_criteria = ee.Filter.date(\n",
        "        dte1.strftime(\"%Y-%m-%d\"), l8_growend.strftime(\"%Y-%m-%d\")\n",
        "    )\n",
        "    s2_criteria = ee.Filter.date(\n",
        "        dte1.strftime(\"%Y-%m-%d\"), s2_growend.strftime(\"%Y-%m-%d\")\n",
        "    )\n",
        "    l8_reduced = l8sr.filter(l8_criteria).median().multiply(0.0000275).add(-0.2).float()\n",
        "    s2_reduced = (\n",
        "        s2Sr.median().divide(10000).float()\n",
        "    )\n",
        "\n",
        "    image = merge_s2_l8(s2_reduced, l8_reduced)\n",
        "    image = img_vi(image).float()\n",
        "    start_year = date(YEAR, 1, 1).strftime(\"%Y-%m-%d\")\n",
        "    end_year = '2022-12-31'\n",
        "    cdl = ee.ImageCollection('USDA/NASS/CDL').filterDate(start_year, end_year).first().select('cropland')\n",
        "\n",
        "    # These numbers determined experimentally.\n",
        "    n = 200  # Number of shards in each polygon.\n",
        "    N = 1000  # Total sample size in each polygon.\n",
        "    # crop_code = int(calendar['Crop Code'])\n",
        "    i = random.randint(0, 100)\n",
        "    data_export = DATA_EXPORTER( image, cdl, kernel, i, binary,30,FOLDER)\n",
        "    for g in states:\n",
        "        trainingPoly = us.filter(ee.Filter.eq(\"ADM1_NAME\", g))\n",
        "        # run_task(arrays,trainingPoly,desc,i)\n",
        "        if binary:\n",
        "            desc = 'binary_{}_{}_{}'.format(crop,g,YEAR).replace(' ','_')\n",
        "            data_export.train_export(trainingPoly,desc)\n",
        "        else:\n",
        "            desc = 'multiclass_{}_{}_{}'.format(crop,g,YEAR).replace(' ','_')\n",
        "            data_export.train_export(trainingPoly,desc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j03RpVyRrUV_"
      },
      "source": [
        "## Export task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPe4G7c9CfkY"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(ee.batch.Task.list())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}